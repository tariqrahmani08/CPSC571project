{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import FunctionTransformer, MinMaxScaler\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from text_clean import *\n",
    "\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "def label_stocks1(df):\n",
    "    labels = []\n",
    "    for i in range(1, len(df.index)):\n",
    "      if df.iloc[i, :]['Close'] - df.iloc[i - 1, :]['Close'] < 0:\n",
    "        labels.append(-1)\n",
    "      else:\n",
    "        labels.append(1)\n",
    "    \n",
    "    df.drop(0, inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df['value'] = pd.Series(labels)\n",
    "\n",
    "\n",
    "def label_stocks2(row):\n",
    "    if row['Close'] >= row['yesterday_close']:\n",
    "        return 1\n",
    "    else:\n",
    "      return 0\n",
    "\n",
    "\n",
    "def concat_headlines(df):\n",
    "    df['text'] = df['text'].apply(lambda x:x + ' ')\n",
    "    df = df.groupby('Date', as_index=False).text.sum()\n",
    "    df['text'] = df['text'].str.lstrip()\n",
    "    \n",
    "\n",
    "apple_stocks = \"Data/Stock data/Stocks/aapl.us.txt\"\n",
    "amazon_stocks = \"Data/Stock data/Stocks/amzn.us.txt\"\n",
    "facebook_stocks = \"Data/Stock data/Stocks/fb.us.txt\"\n",
    "\n",
    "apple_headlines = \"Data/News data/apple_deduped.csv\"\n",
    "amazon_headlines = \"Data/News data/amazon_deduped.csv\"\n",
    "facebook_headlines = \"Data/News data/facebook_deduped.csv\"\n",
    "\n",
    "apple_reddit = \"Data/News data/apple_reddit.csv\"\n",
    "amazon_reddit = \"Data/News data/amazon_reddit.csv\"\n",
    "facebook_reddit = \"Data/News data/facebook_reddit.csv\"\n",
    "\n",
    "apple_tweets = \"Data/Tweets/apple_tweets.csv\"\n",
    "amazon_tweets = \"Data/Tweets/amazon_tweets.csv\"\n",
    "facebook_tweets = \"Data/Tweets/facebook_tweets.csv\"\n",
    "\n",
    "mydateparser = lambda x: pd.datetime.strptime(x[:10], \"%Y-%m-%d\")\n",
    "# df = pd.read_csv('Data/Tweets/apple_tweets.csv', parse_dates=[0], date_parser=mydateparser)\n",
    "df = pd.read_csv(apple_headlines, parse_dates=[1])\n",
    "stock = pd.read_csv(apple_stocks, parse_dates=[0])\n",
    "\n",
    "stock['yesterday_close'] = stock['Close'].shift()\n",
    "stock['yesterday_volume'] = stock['Volume'].shift()\n",
    "stock['value'] = stock.apply(lambda row: label_stocks2(row), axis=1)\n",
    "# label_stocks1(df)\n",
    "\n",
    "# df.rename({'created_at': 'Date'}, inplace=True, axis=1)\n",
    "df = pd.merge(df, stock, on=\"Date\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "df = df[['target', 'value']]\n",
    "\n",
    "pos = df.loc[df['value'] == 1, 'target'].copy().reset_index(drop=True)\n",
    "neg = df.loc[df['value'] == -1, 'target'].copy().reset_index(drop=True)\n",
    "\n",
    "neg = pd.concat([pd.DataFrame(neg), pd.DataFrame(np.zeros(neg.shape), columns=['class'])], 1)\n",
    "pos = pd.concat([pd.DataFrame(pos), pd.DataFrame(np.ones(pos.shape), columns=['class'])], 1)\n",
    "\n",
    "np.random.seed(42)\n",
    "rand = np.random.permutation(pos.shape[0])\n",
    "pos = pos.iloc[rand[:neg.shape[0]]].reset_index(drop=True)\n",
    "\n",
    "df = pd.concat([pos, neg]).sample(frac=1).reset_index(drop=True)\n",
    "\"\"\"\n",
    "\n",
    "for i in ['Open', 'High', 'Low', 'yesterday_volume', 'yesterday_close']:\n",
    "  scaler = MinMaxScaler()\n",
    "  scaled = scaler.fit_transform(df[i].astype('float64').values.reshape(-1, 1))\n",
    "  df[i] = pd.DataFrame(scaled)\n",
    "\n",
    "get_text_data = FunctionTransformer(lambda x: x['text'], validate=False)\n",
    "get_numeric_data = FunctionTransformer(lambda x: x[['Open', 'High', 'Low', 'yesterday_volume', 'yesterday_close']], validate=False)\n",
    "\n",
    "vect = TfidfVectorizer(analyzer='word', strip_accents='unicode', ngram_range=(1, 3), binary=True)\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "            ('numeric_features', Pipeline([\n",
    "                ('selector', get_numeric_data)\n",
    "            ])),\n",
    "              ('text_features', Pipeline([\n",
    "                 ('selector', get_text_data),\n",
    "                 ('vec',  vect)\n",
    "             ]))\n",
    "         ])),\n",
    "    ('clf', LinearSVC(class_weight='balanced'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [   0    1    2 ... 2530 2531 2532] TEST: [2533 2534 2535 ... 5061 5062 5063]\n",
      "TRAIN: [   0    1    2 ... 5061 5062 5063] TEST: [5064 5065 5066 ... 7592 7593 7594]\n",
      "TRAIN: [   0    1    2 ... 7592 7593 7594] TEST: [ 7595  7596  7597 ... 10123 10124 10125]\n",
      "TRAIN: [    0     1     2 ... 10123 10124 10125] TEST: [10126 10127 10128 ... 12654 12655 12656]\n",
      "TRAIN: [    0     1     2 ... 12654 12655 12656] TEST: [12657 12658 12659 ... 15185 15186 15187]\n"
     ]
    }
   ],
   "source": [
    "X = df[['text', 'Open', 'High', 'Low', 'yesterday_volume', 'yesterday_close']]\n",
    "y = df['value']\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "for train_index, test_index in tscv.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('features', FeatureUnion(n_jobs=None,\n",
       "       transformer_list=[('numeric_features', Pipeline(memory=None,\n",
       "     steps=[('selector', FunctionTransformer(accept_sparse=False, check_inverse=True,\n",
       "          func=<function <lambda> at 0x000001A660B4D9D8>, inv_kw_args=None,\n",
       "          inverse_func=N...ax_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0))])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9996707818930041"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 84.86%\n",
      "\n",
      "F1 Score: 85.58\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1213  241]\n",
      " [ 219 1365]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy_score(y_test, y_pred) * 100))\n",
    "print(\"\\nF1 Score: {:.2f}\".format(f1_score(y_test, y_pred) * 100))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
